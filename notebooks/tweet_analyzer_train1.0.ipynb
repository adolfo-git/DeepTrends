{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec0157c6",
   "metadata": {},
   "source": [
    "### Instalación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51dfab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas --upgrade\n",
    "#!pip install gensim --upgrade\n",
    "#!pip install tensorflow --upgrade\n",
    "#!pip install keras --upgrade\n",
    "#!pip install python-Levenshtein --upgrade\n",
    "#!pip install googletrans --upgrade\n",
    "#!pip install xlsxwriter --upgrade\n",
    "#python3 -m spacy download es_dep_news_trf\n",
    "# python -m spacy download es_dep_news_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94bc5461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Scripts\n",
    "from Scripts.TweetCleaner import TweetCleaner\n",
    "from Scripts.SentimentAnalyzer import SentimentAnalyzer\n",
    "\n",
    "# Matplot\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "#plt.style.use('dark_background')\n",
    "#from jupyterthemes import jtplot\n",
    "#jtplot.style(theme=\"monokai\", context=\"notebook\", ticks=True, grid=False)\n",
    "\n",
    "# Utilidad\n",
    "from collections import Counter\n",
    "\n",
    "# Set log\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7683dd29",
   "metadata": {},
   "source": [
    "### Ajustes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d5e7e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "DATASET_COLUMNS = [\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "DATASET_PATH = \"./datasets/no_emoticon_en.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc0ba2d",
   "metadata": {},
   "source": [
    "### Importación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6cc1b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo fichero: ./datasets/no_emoticon_en.csv\n",
      "Tamaño del dataset leído: 1600000 tweets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                          date     query  \\\n",
       "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user  \\\n",
       "0  _TheSpecialOne_   \n",
       "1    scotthamilton   \n",
       "2         mattycus   \n",
       "3          ElleCTF   \n",
       "4           Karoli   \n",
       "\n",
       "                                                                                                                  text  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "1      is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!  \n",
       "2                            @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds  \n",
       "3                                                                      my whole body feels itchy and like its on fire   \n",
       "4      @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Leyendo fichero:\", DATASET_PATH)\n",
    "tweets = pd.read_csv(DATASET_PATH, encoding =DATASET_ENCODING , names=DATASET_COLUMNS)\n",
    "print(f\"Tamaño del dataset leído: {len(tweets)} tweets\")\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "315f34c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_es = pd.read_csv(\"./datasets/no_emoticon_es.csv\", header=None)\n",
    "text_es.columns = [\"text\"]\n",
    "tweets[\"text\"] = text_es[\"text\"]\n",
    "tweets = tweets.dropna()\n",
    "tweets = tweets.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbcf3de",
   "metadata": {},
   "source": [
    "### Variables\n",
    "<ul>\n",
    "    <li><b>sentiment:</b> nivel de sentimiento del tweet (0 = negativo, 2 = neutral, 4 = positivo)</li>\n",
    "    <li><b>id:</b> ID del tweet</li>\n",
    "    <li><b>date:</b> Fecha y hora del tweet (Sat May 16 23:58:44 UTC 2009)</li>\n",
    "    <li><b>query:</b> La consulta realizada para buscar el tweet. El valor por defecto es NO_QUERY.</li>\n",
    "    <li><b>user:</b> Usuario que ha tweeteado</li>\n",
    "    <li><b>text:</b> El propio texto del Tweet</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d6bebc",
   "metadata": {},
   "source": [
    "### Traducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd61fb3",
   "metadata": {},
   "source": [
    "Las siguientes líneas sirven para traducir un dataset de tweets dado utilizando una de las APIs de Google. Es un proceso bastante costoso computacionalmente, principalmente porque es un servicio gratuito que no está pensado para traducir grandes cantidades de información. Tras realizar varias pruebas, se llegó a la conculusión de que si el dataset se subdivide en pequeños paquetes de tweets de no mucho tamaño y se realizan peticiones independientes para cada uno de ellos, se obtiene un throughput aceptable. Además que la pérdida de tweets que no se pueden traducir por problemas con la codificación o por timeout con la muestra de 1.600.000 tweets no fue de más del 0.0125%. La traducción es ofrecida por Google, por lo que la calidad de la traducción no está nada mal, y más aun cuando al fin y al cabo tienes que preprocesar esos datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dffac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = TweetTranslator(text)\n",
    "#t.translate(\"./datasets/no_emoticon_es.csv\", \"en\", \"es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f0aea2",
   "metadata": {},
   "source": [
    "### Preprocesado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60433a4",
   "metadata": {},
   "source": [
    "En primer lugar, haremos un preprocesado de los datos. Este paso es fundamental si queremos conseguir un modelo de calidad, y más aún si se trata de procesar textos tan poco estructurados y caóticos como pueden llegar a ser los tweets. Se preveé que haya gran cantidad de faltas de ortografía y palabras informales o abreviadas, además de que un tweet suele contener menciones y hashtags. Trataremos de normalizando atendiendo a los siguientes criterios:\n",
    "<ul>\n",
    "    <li><b>Menciones:</b> Las menciones como tal no aportan nada al mensaje, pero aunque las eliminemos del propio texto del tweet, las guardaremos en una variable a parte por si se quiere en un fututo estudiar las relaciones entre los usuarios.</li>\n",
    "    <li><b>Hashtags:</b> No queda muy claro qué hacer con ellos, puesto que en algunos casos pueden ser palabras de gran utilidad (ej: #happy); es decir, podrían tener una gran capacidad predictora del sentimiento. Sin embargo, puede haber otros casos en los que sean palabras sin sentido o una frase escrita sin espacios, la cual puede aportar menos o ser más difícil de analizar. En cualquier caso, nos quedaremos con una solución intermedia, que es quitar el símbolo del hashtag (#) pero mantener la propia palabra como tal, que sea el modelo a la hora de su entrenamiento el que decida si es relevante o no. </li>\n",
    "    <li><b>Hipervínculos:</b> Los hipervínculos no aportan nada, o al menos no resultaría nada sencillo analizar el documento o la imagen a la que redirijiese el enlace. Los eliminamos por completo.</li>\n",
    "    <li><b>Puntuación:</b> Los signos de puntuación como comas, puntos u otros, los eliminamos también de los mensajes. Además, pondremos todas las palabras en minúscula para mejorar la normalización.</li>\n",
    "    <li><b>Stopwords:</b> Las stopwords son también conocidas como pabras vacías, es decir, palabras medianemente comunes en un idioma que no aportan prácticamente significado a una oración, como bien pueden ser artículos, pronombres, adverbios, etc. Resulta interesante construir un buen conjunto de estas palabras y seleccionar con precaución que palabras queremos descartar. Para nuestros datos usaremos un cojunto de una librería de procesamiento de lenguaje natural.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11132545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'consigue', 'eso', 'trata', 'vuestro', 'habrá', 'tenga', 'dias', 'haber', 'os', 'sido', 'no', 'suyo', 'poco', 'aquellos', 'consideró', 'dado', 'bastante', 'de', 'hacia', 'hay', 'dos', 'la', 'poder', 'estados', 'aunque', 'cuenta', 'cinco', 'cuántos', 'les', 'alli', 'podría', 'trabajais', 'haciendo', 'van', 'vuestra', 'al', 'ningunos', 'dicen', 'intento', 'da', 'nos', 'valor', 'vuestras', 'lleva', 'haces', 'medio', 'he', 'está', 'nuevo', 'uso', 'existen', 'llevar', 'fui', 'quizás', 'conmigo', 'cuales', 'nuestras', 'sabeis', 'éstos', 'posible', 'tampoco', 'intentais', 'cuál', 'ellos', 'allí', 'pues', 'sea', 'algunas', 'hoy', 'ha', 'claro', 'porque', 'soy', 'anterior', 'sino', 'fue', 'dónde', 'habían', 'pero', 'estaban', 'puede', 'tendrán', 'alrededor', 'debajo', 'vamos', 'entre', 'hacer', 'buenas', 'ustedes', 'hacerlo', 'dar', 'parece', 'va', 'poca', 'como', 'estaba', 'total', 'algún', 'igual', 'mismos', 'somos', 'bien', 'teneis', 'emplean', 'buena', 'nueva', 'ningunas', 'breve', 'trabaja', 'eramos', 'hecho', 'antano', 'estado', 'del', 'toda', 'pasado', 'sobre', 'explicó', 'ningún', 'nosotras', 'donde', 'ahi', 'tiene', 'salvo', 'paìs', 'estas', 'hasta', 'quien', 'el', 'con', 'dan', 'sabe', 'esa', 'primera', 'otro', 'alguno', 'ser', 'también', 'tanto', 'desde', 'nuevas', 'consiguen', 'podriamos', 'podrian', 'principalmente', 'pesar', 'mia', 'partir', 'arribaabajo', 'te', 'cuanta', 'despues', 'trabajo', 'era', 'contra', 'estoy', 'mencionó', 'entonces', 'ejemplo', 'durante', 'otros', 'hizo', 'aseguró', 'consigo', 'cuánta', 'diferentes', 'ésos', 'fueron', 'sin', 'estará', 'propio', 'me', 'realizado', 'cuántas', 'ademas', 'alguna', 'creo', 'sabes', 'ultimo', 'eres', 'dio', 'añadió', 'podria', 'emplear', 'una', 'decir', 'dia', 'cierta', 'arriba', 'haceis', 'informo', 'lejos', 'su', 'quizas', 'tendrá', 'conseguimos', 'general', 'afirmó', 'empleais', 'primero', 'parte', 'mias', 'quizá', 'menos', 'eras', 'antes', 'intenta', 'según', 'cuáles', 'ésa', 'mientras', 'modo', 'hablan', 'unas', 'pueda', 'cuanto', 'mío', 'yo', 'trabajar', 'nuestros', 'podrán', 'delante', 'pudo', 'segunda', 'tambien', 'ciertas', 'trabajan', 'mí', 'podeis', 'siempre', 'quiere', 'así', 'encuentra', 'ninguno', 'ver', 'pocas', 'las', 'despacio', 'propios', 'tus', 'propia', 'si', 'solamente', 'adrede', 'nadie', 'tan', 'diferente', 'cuantos', 'vosotras', 'sean', 'nuestro', 'fuimos', 'junto', 'algunos', 'aquel', 'mucho', 'trabajamos', 'empleas', 'había', 'cada', 'cuando', 'estos', 'cosas', 'están', 'hace', 'vaya', 'siguiente', 'en', 'final', 'cómo', 'últimas', 'demasiado', 'habia', 'quiza', 'otras', 'expresó', 'verdad', 'han', 'verdadero', 'pueden', 'ti', 'aquellas', 'demás', 'después', 'horas', 'indicó', 'próximos', 'sola', 'hacemos', 'informó', 'supuesto', 'tras', 'nunca', 'ambos', 'podrá', 'hemos', 'míos', 'ésas', 'segundo', 'por', 'misma', 'existe', 'consigues', 'propias', 'pais', 'tuyas', 'tuyo', 'más', 'tal', 'un', 'suya', 'quiénes', 'otra', 'aproximadamente', 'manera', 'largo', 'éste', 'nuestra', 'podrias', 'verdadera', 'contigo', 'aún', 'fuera', 'señaló', 'vais', 'menudo', 'poner', 'aquélla', 'todavía', 'fin', 'conseguir', 'esos', 'ampleamos', 'dieron', 'mías', 'intentan', 'nada', 'mía', 'temprano', 'usted', 'gran', 'muchos', 'que', 'ninguna', 'acuerdo', 'cualquier', 'sería', 'cuánto', 'solos', 'usas', 'sí', 'conocer', 'él', 'serán', 'realizó', 'vez', 'sera', 'tuya', 'tu', 'tener', 'soyos', 'ella', 'ésta', 'quedó', 'uno', 'enfrente', 'estuvo', 'peor', 'le', 'casi', 'pocos', 'estan', 'será', 'seis', 'tercera', 'buenos', 'sé', 'sois', 'solo', 'usan', 'saben', 'ir', 'saber', 'hubo', 'este', 'lo', 'hacen', 'trabajas', 'considera', 'quienes', 'tienen', 'dijeron', 'tuyos', 'sus', 'días', 'través', 'debe', 'usais', 'aquello', 'aquí', 'haya', 'detrás', 'último', 'agregó', 'bueno', 'esta', 'mejor', 'tengo', 'manifestó', 'respecto', 'tuvo', 'ese', 'mayor', 'primeros', 'ése', 'primer', 'sólo', 'mediante', 'ahora', 'estais', 'éstas', 'mucha', 'habla', 'usar', 'dejó', 'estamos', 'hago', 'para', 'pronto', 'cerca', 'tiempo', 'todavia', 'se', 'enseguida', 'segun', 'deben', 'muchas', 'mios', 'muy', 'gueno', 'mismas', 'proximo', 'aquéllos', 'unos', 'nuevos', 'es', 'actualmente', 'mi', 'cual', 'usa', 'debido', 'mis', 'antaño', 'solas', 'empleo', 'mas', 'veces', 'raras', 'última', 'aquéllas', 'bajo', 'ello', 'embargo', 'además', 'suyas', 'tarde', 'quién', 'momento', 'qeu', 'vosotros', 'dentro', 'tú', 'dice', 'pasada', 'luego', 'buen', 'intentar', 'dijo', 'ni', 'ocho', 'asi', 'usamos', 'estar', 'cierto', 'qué', 'intentamos', 'mal', 'adelante', 'apenas', 'cuatro', 'aun', 'eran', 'excepto', 'cuantas', 'tres', 'grandes', 'vuestros', 'queremos', 'realizar', 'aqui', 'son', 'varias', 'atras', 'esas', 'los', 'mismo', 'ayer', 'deprisa', 'ante', 'podrían', 'podriais', 'incluso', 'todo', 'siendo', 'esto', 'ahí', 'ex', 'cuándo', 'tenía', 'dicho', 'todas', 'sabemos', 'todos', 'ellas', 'lugar', 'puedo', 'varios', 'día', 'ciertos', 'hicieron', 'aquél', 'encima', 'comentó', 'sigue', 'nosotros', 'algo', 'repente', 'tenido', 'podemos', 'lado', 'mio', 'voy', 'próximo', 'siete', 'ya', 'tenemos', 'últimos', 'aquella', 'llegó', 'intentas', 'detras'}\n",
      "Mentions removed\n",
      "Hashtags removed\n",
      "Links removed\n",
      "Punctuation removed\n",
      "Stemmed\n",
      "0                             awww bumm deb consigu dav carr terc d\n",
      "1    molest actualiz facebook mensaj text y llor escuel result ¡paj\n",
      "2                             i dov pelot logr ahorr rest sal limit\n",
      "3                                     cuerp sient picazon y incendi\n",
      "4                                     comport absolut loc ¿por vert\n",
      "5                                                            tripul\n",
      "6                                                     necesit abraz\n",
      "7                                     hey vert lluev lol ¿com estas\n",
      "8                                                           nop ten\n",
      "9                                                              muer\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "tc = TweetCleaner(tweets.text)\n",
    "tc.clearAll()\n",
    "text = tc.text\n",
    "print(text.iloc[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11641318",
   "metadata": {},
   "source": [
    "### Análisis descriptivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5727357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-29 16:47:36,562 : INFO : Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2021-07-29 16:47:36,563 : INFO : Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['0', '4'])\n",
      "dict_values([799920, 799520])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Etiquetas del dataset')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_cnt = Counter(tweets.sentiment.astype(\"string\"))\n",
    "print(target_cnt.keys())\n",
    "print(target_cnt.values())\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.bar(\n",
    "    target_cnt.keys(),\n",
    "    target_cnt.values(),\n",
    "    tick_label=[\"Negativo\", \"Positivo\"],\n",
    "    color=[\"darkred\", \"green\"],\n",
    ")\n",
    "plt.title(\"Etiquetas del dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1af1d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "\n",
      "index        0\n",
      "sentiment    0\n",
      "id           0\n",
      "date         0\n",
      "query        0\n",
      "user         0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = tweets.isna().sum()\n",
    "print(f\"Missing values:\\n\\n{missing_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2673c578",
   "metadata": {},
   "source": [
    "Vemos que prácticamente las mitad de los tweets del dataset son negativos y la otra mitad son positivos. No aparece ninguno etiquetado directamente como neutro. En la mayoría de datasets esto también es así, aunque parezca paradójico, puede resultar más subjetivo clasificar a un tweet como neutral que como positivo o negativo. Se tratan de tweets escritos por personas, no de textos que puedan ser descriptivos. La solución más sencilla, es fijar unos umbrales a la hora de predecir nuevos valores. Si un tweet tiene una puntuación de positividad intermedia entre ambos, puede interpretarse que no queda muy claro si el tweets es positivo o negativo, y por lo tanto sería buena opción clasificarlo como neutro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfe2540",
   "metadata": {},
   "source": [
    "### Modelo de análisis de sentimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6562d88c",
   "metadata": {},
   "source": [
    "Utilizaremos un modelo de Deep Learning para clasificar nuestros tweets. Partimos de una colección de tweets etiquetados. Pese a que se ha tratado de normalizarlos y darles una homogeneidad, aún falta encontrar una forma de estudiar las asociaciones entre las palabras de cada uno de ellos, para poder almacenarlos de forma numérica y poder trabajar con ellos. Los pasos a seguir en la modelización serán los siguientes:\n",
    "<ul>\n",
    "    <li><b>Word2Vec:</b> Mediante técnicas de procesamiento de lenguaje natural, se usará una red neuroanl para estudiar las asocaciones entre las palabras de los textos. Una vez entrenado, el objetivo de este modelo será detectar sinónimos o sugerir palabras que presenten cierta relación a partir de una frase dada. De esta manera, tendremos nuestros tweets almacenados en vectores numéricos. </li>\n",
    "    <li><b>Tokenization:</b> El siguiente paso será dividir cada uno de nuestros tweets en tokens. Nosotros partimos de una cadena dada, como por ejemplo ' Pfffdf hoy no me apetece nadar :( ', pues tenemos que dividir dicha sentencia en distintos tokens. Se habla de tokens y no de palabras puesto que no tienen por qué tener una léxica definida pero sí un significado semántico. Como bien puede ser palabras mal escritas ('Pfffdf' indica cansancio o desesperación) o conjuntos de caracteres (':(' indica tristeza).</li>\n",
    "    <li><b>Label encoding:</b> Este paso es bien sencillo, simplemente necesitamos un codificador que nos sirva para convertir nuestras etiquetas a valores numéricos con los que podamos trabajar.</li>\n",
    "    <li><b>Sentiment model:</b> Tras haber procesado nuestros datos de input, construiremos un primer modelo de red neuronal. Un modelo secuencial con una única capa oculta. Estudiaremos los resultados y veremos como podemos ir ajustando el modelo para mejorar nuestras predicciones.</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a869bec3",
   "metadata": {},
   "source": [
    "Inicializamos el analizador de sentimientos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbf144be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\BISITE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "sa = SentimentAnalyzer(tweets, \"text\", \"sentiment\",0,2,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3222d6f",
   "metadata": {},
   "source": [
    "Si se desea entrenar un nuevo modelo y almacenar los resultados, se deben descomentar las tres líneas de código de abajo. Es un proceso bastante costoso, por lo que se pueden guardar y cargar modelos previamente entrenados. En este, cargaremos un conjunto de modelos ya entrenados previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03b0450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN size: 319888\n",
      "TEST size: 1279552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-29 16:47:39,155 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=0, vector_size=300, alpha=0.025)', 'datetime': '2021-07-29T16:47:39.148591', 'gensim': '4.0.1', 'python': '3.8.10 (default, May 19 2021, 13:12:57) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'created'}\n",
      "2021-07-29 16:47:39,155 : INFO : collecting all words and their counts\n",
      "2021-07-29 16:47:39,156 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-07-29 16:47:39,179 : INFO : PROGRESS: at sentence #10000, processed 141010 words, keeping 31392 word types\n",
      "2021-07-29 16:47:39,204 : INFO : PROGRESS: at sentence #20000, processed 281278 words, keeping 52629 word types\n",
      "2021-07-29 16:47:39,230 : INFO : PROGRESS: at sentence #30000, processed 421005 words, keeping 71021 word types\n",
      "2021-07-29 16:47:39,258 : INFO : PROGRESS: at sentence #40000, processed 562002 words, keeping 88076 word types\n",
      "2021-07-29 16:47:39,282 : INFO : PROGRESS: at sentence #50000, processed 702265 words, keeping 104050 word types\n",
      "2021-07-29 16:47:39,306 : INFO : PROGRESS: at sentence #60000, processed 843313 words, keeping 119161 word types\n",
      "2021-07-29 16:47:39,332 : INFO : PROGRESS: at sentence #70000, processed 983901 words, keeping 133350 word types\n",
      "2021-07-29 16:47:39,357 : INFO : PROGRESS: at sentence #80000, processed 1123687 words, keeping 146783 word types\n",
      "2021-07-29 16:47:39,384 : INFO : PROGRESS: at sentence #90000, processed 1263615 words, keeping 160119 word types\n",
      "2021-07-29 16:47:39,411 : INFO : PROGRESS: at sentence #100000, processed 1406197 words, keeping 173406 word types\n",
      "2021-07-29 16:47:39,440 : INFO : PROGRESS: at sentence #110000, processed 1547212 words, keeping 185759 word types\n",
      "2021-07-29 16:47:39,467 : INFO : PROGRESS: at sentence #120000, processed 1688654 words, keeping 198172 word types\n",
      "2021-07-29 16:47:39,492 : INFO : PROGRESS: at sentence #130000, processed 1829240 words, keeping 209860 word types\n",
      "2021-07-29 16:47:39,518 : INFO : PROGRESS: at sentence #140000, processed 1970235 words, keeping 221461 word types\n",
      "2021-07-29 16:47:39,544 : INFO : PROGRESS: at sentence #150000, processed 2111366 words, keeping 232813 word types\n",
      "2021-07-29 16:47:39,570 : INFO : PROGRESS: at sentence #160000, processed 2251828 words, keeping 244047 word types\n",
      "2021-07-29 16:47:39,595 : INFO : PROGRESS: at sentence #170000, processed 2392634 words, keeping 255168 word types\n",
      "2021-07-29 16:47:39,622 : INFO : PROGRESS: at sentence #180000, processed 2534149 words, keeping 265824 word types\n",
      "2021-07-29 16:47:39,647 : INFO : PROGRESS: at sentence #190000, processed 2675434 words, keeping 276686 word types\n",
      "2021-07-29 16:47:39,673 : INFO : PROGRESS: at sentence #200000, processed 2817986 words, keeping 287461 word types\n",
      "2021-07-29 16:47:39,698 : INFO : PROGRESS: at sentence #210000, processed 2959661 words, keeping 297987 word types\n",
      "2021-07-29 16:47:39,724 : INFO : PROGRESS: at sentence #220000, processed 3099808 words, keeping 308266 word types\n",
      "2021-07-29 16:47:39,749 : INFO : PROGRESS: at sentence #230000, processed 3239548 words, keeping 318239 word types\n",
      "2021-07-29 16:47:39,775 : INFO : PROGRESS: at sentence #240000, processed 3380168 words, keeping 328144 word types\n",
      "2021-07-29 16:47:39,800 : INFO : PROGRESS: at sentence #250000, processed 3522648 words, keeping 337958 word types\n",
      "2021-07-29 16:47:39,826 : INFO : PROGRESS: at sentence #260000, processed 3663763 words, keeping 348007 word types\n",
      "2021-07-29 16:47:39,861 : INFO : PROGRESS: at sentence #270000, processed 3804100 words, keeping 357772 word types\n",
      "2021-07-29 16:47:39,887 : INFO : PROGRESS: at sentence #280000, processed 3945867 words, keeping 367363 word types\n",
      "2021-07-29 16:47:39,913 : INFO : PROGRESS: at sentence #290000, processed 4088047 words, keeping 376994 word types\n",
      "2021-07-29 16:47:39,939 : INFO : PROGRESS: at sentence #300000, processed 4229824 words, keeping 386533 word types\n",
      "2021-07-29 16:47:39,965 : INFO : PROGRESS: at sentence #310000, processed 4371228 words, keeping 395914 word types\n",
      "2021-07-29 16:47:39,991 : INFO : collected 405106 word types from a corpus of 4511068 raw words and 319888 sentences\n",
      "2021-07-29 16:47:39,992 : INFO : Creating a fresh vocabulary\n",
      "2021-07-29 16:47:40,169 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 retains 23602 unique words (5.826129457475328%% of original 405106, drops 381504)', 'datetime': '2021-07-29T16:47:40.169895', 'gensim': '4.0.1', 'python': '3.8.10 (default, May 19 2021, 13:12:57) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'prepare_vocab'}\n",
      "2021-07-29 16:47:40,170 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=10 leaves 3921659 word corpus (86.93415838555305%% of original 4511068, drops 589409)', 'datetime': '2021-07-29T16:47:40.170886', 'gensim': '4.0.1', 'python': '3.8.10 (default, May 19 2021, 13:12:57) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'prepare_vocab'}\n",
      "2021-07-29 16:47:40,277 : INFO : deleting the raw counts dictionary of 405106 items\n",
      "2021-07-29 16:47:40,284 : INFO : sample=0.001 downsamples 39 most-common words\n",
      "2021-07-29 16:47:40,284 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 3068240.9111774815 word corpus (78.2%% of prior 3921659)', 'datetime': '2021-07-29T16:47:40.284580', 'gensim': '4.0.1', 'python': '3.8.10 (default, May 19 2021, 13:12:57) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'prepare_vocab'}\n",
      "2021-07-29 16:47:40,451 : INFO : estimated required memory for 23602 words and 300 dimensions: 68445800 bytes\n",
      "2021-07-29 16:47:40,451 : INFO : resetting layer weights\n",
      "2021-07-29 16:47:40,478 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-07-29T16:47:40.478471', 'gensim': '4.0.1', 'python': '3.8.10 (default, May 19 2021, 13:12:57) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'build_vocab'}\n",
      "2021-07-29 16:47:40,479 : INFO : Word2Vec lifecycle event {'msg': 'training model with 8 workers on 23602 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=7', 'datetime': '2021-07-29T16:47:40.479468', 'gensim': '4.0.1', 'python': '3.8.10 (default, May 19 2021, 13:12:57) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size 23602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-29 16:47:41,494 : INFO : EPOCH 1 - PROGRESS: at 51.49% examples, 1572649 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:47:42,417 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:47:42,420 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:47:42,424 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:47:42,429 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:47:42,431 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:47:42,432 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:47:42,433 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:47:42,436 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:47:42,437 : INFO : EPOCH - 1 : training on 4511068 raw words (3068182 effective words) took 1.9s, 1576861 effective words/s\n",
      "2021-07-29 16:47:43,453 : INFO : EPOCH 2 - PROGRESS: at 45.71% examples, 1394470 words/s, in_qsize 16, out_qsize 0\n",
      "2021-07-29 16:47:44,443 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:47:44,449 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:47:44,451 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:47:44,453 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:47:44,457 : INFO : EPOCH 2 - PROGRESS: at 99.33% examples, 1518487 words/s, in_qsize 3, out_qsize 1\n",
      "2021-07-29 16:47:44,457 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:47:44,459 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:47:44,460 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:47:44,460 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:47:44,460 : INFO : EPOCH - 2 : training on 4511068 raw words (3067688 effective words) took 2.0s, 1525159 effective words/s\n",
      "2021-07-29 16:47:45,479 : INFO : EPOCH 3 - PROGRESS: at 53.05% examples, 1612973 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:47:46,431 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:47:46,435 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:47:46,437 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:47:46,437 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:47:46,438 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:47:46,443 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:47:46,446 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:47:46,452 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:47:46,453 : INFO : EPOCH - 3 : training on 4511068 raw words (3068216 effective words) took 2.0s, 1548319 effective words/s\n",
      "2021-07-29 16:47:47,468 : INFO : EPOCH 4 - PROGRESS: at 45.71% examples, 1395976 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:47:48,470 : INFO : EPOCH 4 - PROGRESS: at 97.02% examples, 1485346 words/s, in_qsize 14, out_qsize 0\n",
      "2021-07-29 16:47:48,497 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:47:48,501 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:47:48,511 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:47:48,513 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:47:48,513 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:47:48,514 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:47:48,518 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:47:48,519 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:47:48,519 : INFO : EPOCH - 4 : training on 4511068 raw words (3068598 effective words) took 2.1s, 1493950 effective words/s\n",
      "2021-07-29 16:47:49,531 : INFO : EPOCH 5 - PROGRESS: at 43.96% examples, 1343479 words/s, in_qsize 15, out_qsize 1\n",
      "2021-07-29 16:47:50,536 : INFO : EPOCH 5 - PROGRESS: at 90.18% examples, 1378535 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:47:50,719 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:47:50,719 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:47:50,723 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:47:50,725 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:47:50,727 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:47:50,727 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:47:50,730 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:47:50,732 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:47:50,732 : INFO : EPOCH - 5 : training on 4511068 raw words (3067973 effective words) took 2.2s, 1392451 effective words/s\n",
      "2021-07-29 16:47:51,745 : INFO : EPOCH 6 - PROGRESS: at 48.60% examples, 1484703 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:47:52,749 : INFO : EPOCH 6 - PROGRESS: at 97.68% examples, 1494168 words/s, in_qsize 11, out_qsize 0\n",
      "2021-07-29 16:47:52,768 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:47:52,770 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:47:52,772 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:47:52,773 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:47:52,779 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:47:52,780 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:47:52,781 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:47:52,786 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:47:52,787 : INFO : EPOCH - 6 : training on 4511068 raw words (3067602 effective words) took 2.0s, 1501607 effective words/s\n",
      "2021-07-29 16:47:53,805 : INFO : EPOCH 7 - PROGRESS: at 44.18% examples, 1349302 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:47:54,809 : INFO : EPOCH 7 - PROGRESS: at 89.96% examples, 1374723 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:47:54,987 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:47:54,989 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:47:54,990 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:47:54,995 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:47:54,997 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:47:54,999 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:47:55,002 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:47:55,005 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:47:55,006 : INFO : EPOCH - 7 : training on 4511068 raw words (3068549 effective words) took 2.2s, 1392688 effective words/s\n",
      "2021-07-29 16:47:56,017 : INFO : EPOCH 8 - PROGRESS: at 51.50% examples, 1575853 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:47:56,911 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:47:56,912 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:47:56,913 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:47:56,924 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:47:56,927 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:47:56,929 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:47:56,929 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-29 16:47:56,931 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:47:56,931 : INFO : EPOCH - 8 : training on 4511068 raw words (3068272 effective words) took 1.9s, 1601656 effective words/s\n",
      "2021-07-29 16:47:57,946 : INFO : EPOCH 9 - PROGRESS: at 54.36% examples, 1660992 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:47:58,753 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:47:58,754 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:47:58,759 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:47:58,760 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:47:58,761 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:47:58,768 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:47:58,769 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:47:58,770 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:47:58,771 : INFO : EPOCH - 9 : training on 4511068 raw words (3067523 effective words) took 1.8s, 1678800 effective words/s\n",
      "2021-07-29 16:47:59,788 : INFO : EPOCH 10 - PROGRESS: at 52.59% examples, 1607663 words/s, in_qsize 14, out_qsize 1\n",
      "2021-07-29 16:48:00,612 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:00,612 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:00,616 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:00,621 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:00,621 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:00,622 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:00,629 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:00,629 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:00,630 : INFO : EPOCH - 10 : training on 4511068 raw words (3069216 effective words) took 1.8s, 1664255 effective words/s\n",
      "2021-07-29 16:48:01,651 : INFO : EPOCH 11 - PROGRESS: at 54.36% examples, 1652087 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:48:02,453 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:02,459 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:02,463 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:02,466 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:02,467 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:02,468 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:02,472 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:02,475 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:02,475 : INFO : EPOCH - 11 : training on 4511068 raw words (3069180 effective words) took 1.8s, 1674328 effective words/s\n",
      "2021-07-29 16:48:03,491 : INFO : EPOCH 12 - PROGRESS: at 54.81% examples, 1672643 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:48:04,324 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:04,327 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:04,328 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:04,336 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:04,337 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:04,338 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:04,341 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:04,343 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:04,343 : INFO : EPOCH - 12 : training on 4511068 raw words (3068155 effective words) took 1.9s, 1652989 effective words/s\n",
      "2021-07-29 16:48:05,356 : INFO : EPOCH 13 - PROGRESS: at 54.36% examples, 1662749 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:48:06,164 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:06,167 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:06,170 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:06,170 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:06,171 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:06,172 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:06,176 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:06,178 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:06,178 : INFO : EPOCH - 13 : training on 4511068 raw words (3067832 effective words) took 1.8s, 1682815 effective words/s\n",
      "2021-07-29 16:48:07,191 : INFO : EPOCH 14 - PROGRESS: at 51.71% examples, 1583385 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:48:08,091 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:08,092 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:08,094 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:08,095 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:08,096 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:08,097 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:08,101 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:08,103 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:08,104 : INFO : EPOCH - 14 : training on 4511068 raw words (3069401 effective words) took 1.9s, 1604070 effective words/s\n",
      "2021-07-29 16:48:09,121 : INFO : EPOCH 15 - PROGRESS: at 53.04% examples, 1618634 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:48:09,971 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:09,972 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:09,973 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:09,978 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:09,978 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:09,979 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:09,979 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:09,986 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:09,986 : INFO : EPOCH - 15 : training on 4511068 raw words (3068728 effective words) took 1.9s, 1642369 effective words/s\n",
      "2021-07-29 16:48:10,998 : INFO : EPOCH 16 - PROGRESS: at 54.36% examples, 1664871 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:48:11,806 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:11,808 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:11,809 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:11,810 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:11,812 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:11,815 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:11,819 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:11,826 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:11,826 : INFO : EPOCH - 16 : training on 4511068 raw words (3068789 effective words) took 1.8s, 1678197 effective words/s\n",
      "2021-07-29 16:48:12,842 : INFO : EPOCH 17 - PROGRESS: at 52.37% examples, 1598952 words/s, in_qsize 14, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-29 16:48:13,700 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:13,701 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:13,703 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:13,704 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:13,708 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:13,710 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:13,711 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:13,711 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:13,712 : INFO : EPOCH - 17 : training on 4511068 raw words (3068405 effective words) took 1.9s, 1637523 effective words/s\n",
      "2021-07-29 16:48:14,727 : INFO : EPOCH 18 - PROGRESS: at 55.03% examples, 1680033 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:48:15,549 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:15,552 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:15,552 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:15,553 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:15,553 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:15,558 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:15,559 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:15,560 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:15,560 : INFO : EPOCH - 18 : training on 4511068 raw words (3067538 effective words) took 1.8s, 1670846 effective words/s\n",
      "2021-07-29 16:48:16,574 : INFO : EPOCH 19 - PROGRESS: at 51.04% examples, 1556290 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:48:17,481 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:17,483 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:17,487 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:17,489 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:17,490 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:17,494 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:17,495 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:17,496 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:17,497 : INFO : EPOCH - 19 : training on 4511068 raw words (3068786 effective words) took 1.9s, 1592534 effective words/s\n",
      "2021-07-29 16:48:18,509 : INFO : EPOCH 20 - PROGRESS: at 53.49% examples, 1636019 words/s, in_qsize 16, out_qsize 0\n",
      "2021-07-29 16:48:19,360 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:19,362 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:19,375 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:19,376 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:19,377 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:19,377 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:19,384 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:19,385 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:19,385 : INFO : EPOCH - 20 : training on 4511068 raw words (3068614 effective words) took 1.9s, 1634998 effective words/s\n",
      "2021-07-29 16:48:20,400 : INFO : EPOCH 21 - PROGRESS: at 53.47% examples, 1636393 words/s, in_qsize 14, out_qsize 1\n",
      "2021-07-29 16:48:21,267 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:21,270 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:21,275 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:21,277 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:21,277 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:21,278 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:21,279 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:21,285 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:21,285 : INFO : EPOCH - 21 : training on 4511068 raw words (3067584 effective words) took 1.9s, 1626525 effective words/s\n",
      "2021-07-29 16:48:22,300 : INFO : EPOCH 22 - PROGRESS: at 52.59% examples, 1605199 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:48:23,099 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:23,102 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:23,105 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:23,107 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:23,110 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:23,111 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:23,112 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:23,115 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:23,115 : INFO : EPOCH - 22 : training on 4511068 raw words (3068935 effective words) took 1.8s, 1687531 effective words/s\n",
      "2021-07-29 16:48:24,129 : INFO : EPOCH 23 - PROGRESS: at 51.71% examples, 1580555 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:48:25,043 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:25,044 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:25,056 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:25,057 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:25,061 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:25,062 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:25,062 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:25,065 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:25,065 : INFO : EPOCH - 23 : training on 4511068 raw words (3068387 effective words) took 1.9s, 1583195 effective words/s\n",
      "2021-07-29 16:48:26,078 : INFO : EPOCH 24 - PROGRESS: at 54.36% examples, 1664519 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:48:26,849 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:26,850 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:26,851 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:26,860 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:26,860 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:26,868 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:26,869 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:26,869 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:26,870 : INFO : EPOCH - 24 : training on 4511068 raw words (3068660 effective words) took 1.8s, 1712182 effective words/s\n",
      "2021-07-29 16:48:27,885 : INFO : EPOCH 25 - PROGRESS: at 54.14% examples, 1652431 words/s, in_qsize 16, out_qsize 0\n",
      "2021-07-29 16:48:28,647 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:28,654 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:28,656 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:28,657 : INFO : worker thread finished; awaiting finish of 4 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-29 16:48:28,660 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:28,661 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:28,665 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:28,666 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:28,666 : INFO : EPOCH - 25 : training on 4511068 raw words (3068167 effective words) took 1.8s, 1719405 effective words/s\n",
      "2021-07-29 16:48:29,686 : INFO : EPOCH 26 - PROGRESS: at 52.37% examples, 1590553 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:48:30,507 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:30,512 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:30,521 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:30,522 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:30,524 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:30,525 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:30,528 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:30,530 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:30,530 : INFO : EPOCH - 26 : training on 4511068 raw words (3067700 effective words) took 1.9s, 1656059 effective words/s\n",
      "2021-07-29 16:48:31,546 : INFO : EPOCH 27 - PROGRESS: at 51.06% examples, 1556055 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:48:32,386 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:32,389 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:32,393 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:32,397 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:32,398 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:32,400 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:32,400 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:32,405 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:32,406 : INFO : EPOCH - 27 : training on 4511068 raw words (3068437 effective words) took 1.9s, 1646396 effective words/s\n",
      "2021-07-29 16:48:33,425 : INFO : EPOCH 28 - PROGRESS: at 53.70% examples, 1631950 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:48:34,183 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:34,186 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:34,192 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:34,193 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:34,196 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:34,197 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:34,198 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:34,200 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:34,201 : INFO : EPOCH - 28 : training on 4511068 raw words (3068628 effective words) took 1.8s, 1720162 effective words/s\n",
      "2021-07-29 16:48:35,214 : INFO : EPOCH 29 - PROGRESS: at 53.26% examples, 1629704 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:48:36,043 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:36,046 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:36,047 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:36,048 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:36,051 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:36,055 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:36,056 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:36,057 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:36,058 : INFO : EPOCH - 29 : training on 4511068 raw words (3068745 effective words) took 1.8s, 1663115 effective words/s\n",
      "2021-07-29 16:48:37,071 : INFO : EPOCH 30 - PROGRESS: at 52.60% examples, 1609100 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:48:37,934 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:37,939 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:37,941 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:37,948 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:37,949 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:37,953 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:37,955 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:37,958 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:37,959 : INFO : EPOCH - 30 : training on 4511068 raw words (3068877 effective words) took 1.9s, 1624949 effective words/s\n",
      "2021-07-29 16:48:38,975 : INFO : EPOCH 31 - PROGRESS: at 55.03% examples, 1677213 words/s, in_qsize 14, out_qsize 1\n",
      "2021-07-29 16:48:39,756 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:39,766 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:39,768 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:39,771 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:39,772 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:39,773 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:39,774 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:39,777 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:39,777 : INFO : EPOCH - 31 : training on 4511068 raw words (3068121 effective words) took 1.8s, 1697883 effective words/s\n",
      "2021-07-29 16:48:40,792 : INFO : EPOCH 32 - PROGRESS: at 55.03% examples, 1679994 words/s, in_qsize 15, out_qsize 0\n",
      "2021-07-29 16:48:41,564 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2021-07-29 16:48:41,569 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2021-07-29 16:48:41,575 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2021-07-29 16:48:41,578 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2021-07-29 16:48:41,581 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-07-29 16:48:41,582 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-07-29 16:48:41,587 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-07-29 16:48:41,589 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-07-29 16:48:41,590 : INFO : EPOCH - 32 : training on 4511068 raw words (3068099 effective words) took 1.8s, 1703583 effective words/s\n",
      "2021-07-29 16:48:41,590 : INFO : Word2Vec lifecycle event {'msg': 'training on 144354176 raw words (98187587 effective words) took 61.1s, 1606719 effective words/s', 'datetime': '2021-07-29T16:48:41.590684', 'gensim': '4.0.1', 'python': '3.8.10 (default, May 19 2021, 13:12:57) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19042-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words 258489\n",
      "y_train (319888, 1)\n",
      "y_test (1279552, 1)\n",
      "x_train (319888, 300)\n",
      "y_train (319888, 1)\n",
      "\n",
      "x_test (1279552, 300)\n",
      "y_test (1279552, 1)\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-29 16:49:23,441 : WARNING : Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 300)          77546700  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 77,707,201\n",
      "Trainable params: 160,501\n",
      "Non-trainable params: 77,546,700\n",
      "_________________________________________________________________\n",
      "Epoch 1/8\n",
      "2250/2250 [==============================] - 2715s 1s/step - loss: 0.5641 - acc: 0.7033 - val_loss: 0.4887 - val_acc: 0.7658\n",
      "Epoch 2/8\n",
      " 397/2250 [====>.........................] - ETA: 36:31 - loss: 0.5055 - acc: 0.7515"
     ]
    }
   ],
   "source": [
    "sa.build_model()\n",
    "sa.fit_model(batch_size = 128, epochs = 8)\n",
    "sa.save_data(\"models\")\n",
    "#sa.load_data(\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f22fd84",
   "metadata": {},
   "source": [
    "### Resultados del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85c6a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d154ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.plot_confusion_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab14d5e",
   "metadata": {},
   "source": [
    "Podemos ver que para un primer modelo inicial, no está mal. Tenemos una capacidad predictora del 80% aproximadamente, también debido a que parte de ese 20% son tweets que tienen un score de positividad medio, y por tanto hemos clasificado como neutros, en lugar de clasificarlos simplemente como positivo o negativo. Fijándonos en la sensibilidad y la especificidad vemos que son también del 80%; es decir, tenemos la misma capacidad predictora tanto para tweets negativos como positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78946ee7",
   "metadata": {},
   "source": [
    "### Predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e920f94",
   "metadata": {},
   "source": [
    "Finalmente, vamos a realizar una serie de predicciones para ver como se comporta nuestro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c62a694",
   "metadata": {},
   "source": [
    "Cumplido a una persona. Esperamos que lo clasifique como positivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae9e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.predict(\"Qué genial es tu sombrero\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba5fc03",
   "metadata": {},
   "source": [
    "Mensaje de odio hacia una persona. Esperamos que lo clasifique como negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b646cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.predict(\"Que pesado es, no lo soporto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5deb24",
   "metadata": {},
   "source": [
    "Mensaje descriptivo, sin entrar en valoraciones. Esperamos que lo clasifique como neutro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f25126",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.predict(\"simplemente es así, sin más\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
